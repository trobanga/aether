# Aether DUP Pipeline Configuration Example
# Copy this file to aether.yaml and customize for your environment

services:
  # TORCH Data Extraction Server (optional)
  # Used for extracting FHIR cohort data directly via CRTDL files
  # Leave empty to skip TORCH integration
  torch:
    # TORCH server base URL
    base_url: "http://localhost:8080"

    # TORCH file server URL (optional - for downloading extraction files)
    # If not specified, uses base_url for file downloads
    # In Docker setups, this is typically the nginx container serving the output files
    file_server_url: "http://localhost:8082"

    # TORCH authentication credentials
    username: "test"
    password: "test"

    # Maximum time to wait for extraction completion (in minutes)
    # Default: 30 minutes (reasonable for typical cohort sizes)
    extraction_timeout_minutes: 30

    # Initial polling interval when checking extraction status (in seconds)
    # Default: 5 seconds
    polling_interval_seconds: 5

    # Maximum polling interval (exponential backoff cap, in seconds)
    # Default: 30 seconds
    max_polling_interval_seconds: 30
  
  # DIMP Pseudonymization Service (optional)
  # Leave empty to skip pseudonymization step
  dimp:
    url: "http://localhost:32861/fhir"

  # CSV Conversion Service (optional)
  # Leave empty to skip CSV conversion
  csv_conversion:
    url: "http://localhost:9000/convert/csv"

  # Parquet Conversion Service (optional)
  # Leave empty to skip Parquet conversion
  parquet_conversion:
    url: "http://localhost:9000/convert/parquet"

pipeline:
  # List of steps to execute in order
  # Options: import, dimp, validation, csv_conversion, parquet_conversion
  # NOTE: 'import' must always be the first step
  enabled_steps:
    - import
    - dimp
    - csv_conversion
    - parquet_conversion

retry:
  # Maximum number of retry attempts for transient errors (network, 5xx)
  # Range: 1-10
  max_attempts: 5

  # Initial backoff delay in milliseconds
  initial_backoff_ms: 1000

  # Maximum backoff delay in milliseconds (exponential backoff cap)
  max_backoff_ms: 30000

# Directory to store job state and data
# Can be absolute or relative path
jobs_dir: "./jobs"
